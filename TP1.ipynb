{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"./LogoSU.jpg\" width=\"200\" title=\"SU\">\n",
    "\n",
    "<br>\n",
    "\n",
    "<center>\n",
    "<h1>MU4PY115 - IA pour la physique</h1>\n",
    "<h1>TP n°1 : méthode des k plus proches voisins</h1>\n",
    "</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "Cette séance de TP a pour objectifs de présenter l'algorithme des $k$ plus proches voisins et la méthode de validation croisée ainsi que d'introduire les bases de l'utilisation de la librairie scikit-learn (https://scikit-learn.org/stable/index.html) couramment utilisée en machine learning. Cette librairie inclu un grande nombre d'algorithmes d'apprentissage statistique (supervisés et non supervisés) ainsi que des fonctions facilitant la préparation des données et l'anayse des performances. Pour cette séance de TP ainsi que pour les suivantes, je vous encourage très fortement à consulter la documentation de cette librairie, notamment la section API qui contient la description précise de toutes les méthodes disponibles."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T15:21:35.414976400Z",
     "start_time": "2023-09-22T15:21:35.367266100Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.random\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (7, 7)\n",
    "plt.rcParams[\"font.size\"] = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Partie 1: jeu de données 2D\n",
    "\n",
    "Afin de pouvoir visualiser les différentes étape du processus de traitement, nous allons commencer par travailler sur des données 2D générées artificiellement.\n",
    "\n",
    "### Génération des données\n",
    "\n",
    "- Utilisez la fonction <code>numpy.random.multivariate_normal()</code> afin de générer 2 variables $X_A$ et $X_B$ correspondant à 2 nuages de points (2D) contenant chacun n=200 points répartis suivant une distribution gaussien 2D. $X_A$ et $X_B$ seront donc des tableaux de dimension $n \\times 2$.\n",
    "- Représentez les données sur un graphe à l'aide des fonctions <code>pyplot.plot()</code> ou <code>pyplot.scatter()</code>. Vous choisirez le centre et la variance des distributions de façon à ce que les 2 nuages de points se recouvrent partiellement. N'oubliez pas de donner un nom aux axes et d'afficher la légende sur le graphe.\n",
    "- Créez les variables $y_A$ et $y_B$  correspondant aux étiquettes des données, en prenant $y=0$ pour la classe A et $y=1$ pour la classe B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T15:21:35.980212500Z",
     "start_time": "2023-09-22T15:21:35.632176300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Création des données correspondant aux deux classes\n",
    "mean_A = [-1,-1]\n",
    "cov_A = [[1,0],[0,1]]\n",
    "mean_B = [1,1]\n",
    "cov_B = [[0.5,0],[0,0.5]]\n",
    "\n",
    "X_A = np.ones((2,200))\n",
    "X_B = np.ones((2,200))\n",
    "\n",
    "X_A[0], X_A[1] = numpy.random.multivariate_normal(mean_A, cov_A, size = 200).T\n",
    "X_B[0], X_B[1] = numpy.random.multivariate_normal(mean_B, cov_B, size = 200).T\n",
    "print(X_A, X_B[0].shape)\n",
    "\n",
    "# A et B et représentation des données sur un graphe\n",
    "plt.plot(X_B[0],X_B[1],'o', label='Données B')\n",
    "plt.plot(X_A[0], X_A[1],'o', label='Données A')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Y_A = np.zeros(200)\n",
    "Y_B = np.ones(200)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T15:21:36.098387400Z",
     "start_time": "2023-09-22T15:21:35.951454700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A l'aide des fonctions <code>numpy.append()</code> ou <code>numpy.concatenate()</code>, rassemblez les 2 groupes de données sous la forme d'une variable $X$ de dimension $2n \\times 2$ et une variable $y$ de dimension $2n$. Affichez à l'écran les dimensions des 2 variables créées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T15:21:36.410543500Z",
     "start_time": "2023-09-22T15:21:36.292328200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Création des variables $X$ et $y$\n",
    "X = np.zeros((2,400))\n",
    "X[0] = numpy.append(X_A[0],X_B[0])\n",
    "X[1] = numpy.append(X_A[1],X_B[1])\n",
    "Y = numpy.append(Y_A,Y_B)\n",
    "\n",
    "print(X)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mélangez les données à l'aide de la fonction <code>numpy.random.shuffle()</code>.\n",
    "- En utilisant les variables $X$ et $y$, représentez à nouveau les données sur un graphe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T15:21:37.787648Z",
     "start_time": "2023-09-22T15:21:37.488766300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Mélange des données\n",
    "arr = np.arange(400)\n",
    "numpy.random.shuffle(arr)\n",
    "arr\n",
    "\n",
    "newX = X.copy()\n",
    "newY = Y.copy()\n",
    "for i in range(400):\n",
    "    newX[0][i] = X[0][arr[i]]\n",
    "    newX[1][i] = X[1][arr[i]]\n",
    "    newY[i] = Y[arr[i]]\n",
    "\n",
    "# A et B et représentation des données sur un graphe\n",
    "plt.plot(newX[0,newY==0],newX[1, newY==0],'ro', label='Données A')\n",
    "plt.plot(newX[0,newY==1],newX[1, newY==1],'bo', label='Données B')\n",
    "plt.xlabel('$X_1$')\n",
    "plt.ylabel('$X_2$')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Assemblez les éléments définis ci-dessus pour créer une fonction prenant en argument le nombre $n$ de données dans chaque classe, le centre et la variance de chaque distribution, et renvoyant en sortie les variables $X$ et $y$ après mélange."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T15:21:39.228960500Z",
     "start_time": "2023-09-22T15:21:39.212761300Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_data(center_A : [float], sig_A: float, n_A: int, center_B: [float], sig_B: float, n_B: int):\n",
    "    \n",
    "    #Création $X_A$ et $X_B$\n",
    "    \n",
    "    mean_A = center_A\n",
    "    cov_A = [[sig_A**2,0],[0,sig_A**2]]\n",
    "    mean_B = center_B\n",
    "    cov_B = [[sig_B**2,0],[0,sig_B**2]]\n",
    "    \n",
    "    X_A = np.ones((2,n_A))\n",
    "    X_B = np.ones((2,n_B))\n",
    "    \n",
    "    X_A[0], X_A[1] = numpy.random.multivariate_normal(mean_A, cov_A, size = n_A).T\n",
    "    X_B[0], X_B[1] = numpy.random.multivariate_normal(mean_B, cov_B, size = n_B).T\n",
    "    \n",
    "    # Création $Y_A$ et $Y_B$\n",
    "    \n",
    "    Y_A = np.zeros(n_A)\n",
    "    Y_B = np.ones(n_B)\n",
    "    \n",
    "    # Création des variables $X$ et $y$\n",
    "    X = np.zeros((2,n_A+n_B))\n",
    "    X[0] = numpy.append(X_A[0],X_B[0])\n",
    "    X[1] = numpy.append(X_A[1],X_B[1])\n",
    "    Y = numpy.append(Y_A,Y_B)\n",
    "    \n",
    "    # Mélange des données\n",
    "    arr = np.arange(n_A + n_B)\n",
    "    numpy.random.shuffle(arr)\n",
    "    \n",
    "    newX = X.copy()\n",
    "    newY = Y.copy()\n",
    "    for i in range(n_A + n_B):\n",
    "        newX[0][i] = X[0][arr[i]]\n",
    "        newX[1][i] = X[1][arr[i]]\n",
    "        newY[i] = Y[arr[i]]\n",
    "    \n",
    "    return newX.T, newY.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partitionnement des données\n",
    "\n",
    "Ces données vont maintenant être utilisées pour construire une fonction capable de prédire la classe à laquelle doit appartenir une nouvelle donnée $x_{new}$. Pour évaluer les performances de cette fonction, il faut que l'on dispose de données pour lesquelles on connaît la classe correspondante. Cependant, il n'est pas possible d'utiliser les mêmes données à la fois pour entraîner l'algorithme et pour l'évaluer car cette évaluation serait faussée. L'évaluation du modèle doit impérativement être effectuée avec des données qui n'ont pas été utilisées pour l'apprentissage afin de refléter la performance que l'on peut attendre du modèle pour de nouvelles données.\n",
    "\n",
    "<br>\n",
    "\n",
    "- Utilisez la fonction <code>train_test_split()</code> du module <code>sklearn.model_selection</code> afin de séparer les données $(X,y)$ initialement créées en un jeu d'entraînement contenant 70% des données et un jeu de test contenant les 30% restant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T15:21:40.723902800Z",
     "start_time": "2023-09-22T15:21:40.626770100Z"
    }
   },
   "outputs": [],
   "source": [
    "# séparation des données à l'aide de la fonction train_test_split()\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X,y = create_data([-1,-1],0.5,300,[1,1],0.9,50)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,train_size=0.7, stratify=y)\n",
    "print(f\"X_train : {X_train.shape}, X_test : {X_test.shape}, y_train : {y_train.shape}, y_test : {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Comment doit-on paramétrer cette fonction pour pouvoir obtenir le même partitionnement si l'on utilise cette fonction plusieurs fois sur le mêmes données $(X,y)$ ?\n",
    "\n",
    "On met le paramètre random_state égal au même int !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Comment doit-on paramétrer cette fonction pour que la répartition des étiquettes dans les 2 jeux créés soit identique à celle du jeu de départ ?\n",
    "\n",
    "On met une valeur dans stratify."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entraînement et évaluation d'un modèle avec scikit-learn\n",
    "\n",
    "Vous allez maintenant appliquer aux données d'entraînement le modèle des $k$ plus proches voisins implémenté dans la bibliothèque scikit-learn. Tous les algorithmes d'aprentissage supervisés implémentés dans cette bibliothèque s'utilisent de la même façon. Un modèle ($k$ plus proches voisins, régression linéaire, réseau de neurones, etc) correspond à une classe python. Il faut donc tout d'abord\n",
    "1. importer la classe correspondante\n",
    "2. créer une instance de cette classe, c'est à dire créer un objet du type de cette classe\n",
    "\n",
    "Pour un classificateur de type $k$ plus proches voisins cela donnerait:\n",
    "\n",
    "```python\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier()\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "Lors de l'étape d'instanciation, il est possible de passer en argument différents paramètres permettant de contrôler le fonctionnement de l'algorithme. Dans le cas d'un modèle de $k$ plus proches voisins, on peut par exemple indiquer le nombre de plus proches voisins considérés.\n",
    "\n",
    "On peut ensuite entraîner le modèle grâce à la méthode <code>.fit()</code> et calculer le score du modèle grâce à la méthode <code>.score()</code>.<br>\n",
    "\n",
    "Enfin, la méthode <code>.predict()</code> permet de prédire la classe pour de nouvelles données.\n",
    "\n",
    "<br>\n",
    "\n",
    "- Entraînez un modèle de type <code>KNeighborsClassifier()</code> pour $k=1$.\n",
    "- Calculez le score sur les jeux d'entraînement et de test. A quelle grandeur correspond la valeur renvoyée ? Comment pouvez-vous expliquer la valeur obtenue pour le score d'entraînement ?\n",
    "\n",
    "Elle équivaut à la moyenne de la prédiction (0 si fausse, 1 si correcte). On obtient 1 pour le score d'entrainement car tout les points d'entrainement sont les plus proches d'eux même, et sont donc prédits avec leur propre étiquette\n",
    "\n",
    "- Calculez les étiquettes prédites pour les données de test. Représentez sur un graphe les données d'entraînement et les données de test avec leur étiquette vraie et leur étiquette prédite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T15:21:43.122913100Z",
     "start_time": "2023-09-22T15:21:42.909069900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Entraînement et évaluation du modèle pour k=1\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier(n_neighbors=1,weights='distance')\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "print(model.score(X_train,y_train))\n",
    "y_predict = model.predict(X_test)\n",
    "print(model.score(X_test,y_test))\n",
    "\n",
    "# A et B et représentation des données sur un graphe\n",
    "plt.plot(X_train.T[0,y_train==0],X_train.T[1, y_train==0],'bo', label=\"Données A d'entrainement\")\n",
    "plt.plot(X_train.T[0,y_train==1],X_train.T[1, y_train==1],'bo', label=\"Données B d'entrainement\")\n",
    "\n",
    "plt.plot(X_test.T[0,y_predict==y_test],X_test.T[1, y_predict==y_test],'b^', label=\"Données de test vraie\")\n",
    "plt.plot(X_test.T[0,y_predict!=y_test],X_test.T[1, y_predict!=y_test],'r^', label=\"Donnée de test fausses\")\n",
    "\n",
    "plt.xlabel('$X_1$')\n",
    "plt.ylabel('$X_2$')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Entraînez à nouveau un modèle de $k$ plus proches voisins sur ces données, mais pour $k=5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T15:21:47.226869400Z",
     "start_time": "2023-09-22T15:21:46.997746600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Entraînement et évaluation du modèle pour k=5\n",
    "model = KNeighborsClassifier(n_neighbors=5,weights='distance')\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "print(model.score(X_train,y_train))\n",
    "y_predict = model.predict(X_test)\n",
    "print(model.score(X_test,y_test))\n",
    "\n",
    "# A et B et représentation des données sur un graphe\n",
    "plt.plot(X_train.T[0,y_train==0],X_train.T[1, y_train==0],'bo', label=\"Données A d'entrainement\")\n",
    "plt.plot(X_train.T[0,y_train==1],X_train.T[1, y_train==1],'b^', label=\"Données B d'entrainement\")\n",
    "\n",
    "plt.plot(X_test.T[0,y_predict==y_test],X_test.T[1, y_predict==y_test],'b^', label=\"Données de test vraie\")\n",
    "plt.plot(X_test.T[0,y_predict!=y_test],X_test.T[1, y_predict!=y_test],'r^', label=\"Donnée de test fausses\")\n",
    "\n",
    "plt.xlabel('$X_1$')\n",
    "plt.ylabel('$X_2$')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Que peut-on constater ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evolutions des performances en fonction de la valeur de k\n",
    "\n",
    "- A l'aide d'une boucle, créez et entraînez un modèle de $k$ plus proches voisins en faisant varier $k$ entre 1 et 50.\n",
    "- Pour chaque modèle calculez le score obtenu pour les données d'entraînement et pour les données de test.\n",
    "- Représentez ces scores sur un graphe, en fonction de $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T15:22:00.178436600Z",
     "start_time": "2023-09-22T15:21:58.924335500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calcul du score d'entraînement et du score de test pour des valeurs de $k$ comprises \n",
    "# entre 1 et 50\n",
    "\n",
    "X,y = create_data([-0.5,-0.5],0.5,1000,[0.5,0.5],0.9,500)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,train_size=0.7, stratify=y)\n",
    "# A et B et représentation des données sur un graphe\n",
    "plt.plot(X_train.T[0,y_train==0],X_train.T[1, y_train==0],'bo', label=\"Données A d'entrainement\")\n",
    "plt.plot(X_train.T[0,y_train==1],X_train.T[1, y_train==1],'ro', label=\"Données B d'entrainement\")\n",
    "\n",
    "plt.xlabel('$X_1$')\n",
    "plt.ylabel('$X_2$')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "def scoreKneighbors(k: int):\n",
    "    model = KNeighborsClassifier(n_neighbors=k,weights='distance')\n",
    "    model.fit(X_train,y_train)\n",
    "    \n",
    "    score_train = model.score(X_train,y_train)\n",
    "    score_test = model.score(X_test,y_test)\n",
    "    \n",
    "    return score_test, score_train\n",
    "\n",
    "list_score_test = []\n",
    "list_score_train = []\n",
    "for i in range(1,51):\n",
    "    score_test, score_train = scoreKneighbors(i)\n",
    "    list_score_test.append(score_test)\n",
    "    list_score_train.append(score_train)\n",
    "\n",
    "k = np.arange(1,51)\n",
    "plt.plot(k,list_score_test, label=\"Score de test\")\n",
    "plt.plot(k,list_score_train, label=\"Score d'entraînement\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Est-ce que l'utilisation de ces courbes constitue une bonne méthode pour déterminer la valeur optimale de $k$ ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Méthode de validation croisée\n",
    "\n",
    "- Utilisez la fonction <code>cross_validate()</code> du module <code>sklearn.model_selection</code> afin de calculer les scores pour $k$=1 dans le cas d'une validation croisée à 5 blocs sur les données d'entraînement.\n",
    "- Affichez la valeur du score pour chaque bloc ainsi que le score moyen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T15:22:03.761344400Z",
     "start_time": "2023-09-22T15:22:03.671214200Z"
    }
   },
   "outputs": [],
   "source": [
    "# validation croisée à 5 blocs sur les données d'entraînement pour k=1\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "cross_validate(model, X_train, y_train, cv=5)['test_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Utilisez la fonction <code>GridSearchCV()</code> du module <code>sklearn.model_selection</code> afin de déterminer le nombre optimal de voisins $k$. Vous afficherez à l'écran le score de validation pour toutes les valeurs de $k$ comprises entre 1 et 20 (utilisez l'attribut <code>.cv_results_</code>)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T15:22:07.879689300Z",
     "start_time": "2023-09-22T15:22:04.815517600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Détermination du paramètre k optimal par recherche sur grille avec validation croisée\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X,y = create_data([-1,-1],1,1000,[1,1],1,500)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,train_size=0.7, stratify=y)\n",
    "# A et B et représentation des données sur un graphe\n",
    "plt.plot(X_train.T[0,y_train==0],X_train.T[1, y_train==0],'bo', label=\"Données A d'entrainement\")\n",
    "plt.plot(X_train.T[0,y_train==1],X_train.T[1, y_train==1],'ro', label=\"Données B d'entrainement\")\n",
    "\n",
    "plt.xlabel('$X_1$')\n",
    "plt.ylabel('$X_2$')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "parameter = {'n_neighbors': range(1,101)}\n",
    "knn = KNeighborsClassifier(weights='distance')\n",
    "GSCV = GridSearchCV(knn, parameter, cv=5)\n",
    "GSCV.fit(X_train, y_train)\n",
    "results = GSCV.cv_results_['mean_test_score']\n",
    "\n",
    "plt.plot(np.arange(1,101), results)\n",
    "plt.show()\n",
    "\n",
    "best_k = results.argmax()\n",
    "print(f\"Best k is {best_k}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Entraînez le modèle avec l'ensemble des données d'entraînement pour la valeur optimale de $k$ puis évaluez les performances du modèle ainsi obtenu pour les données de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T15:22:08.012388800Z",
     "start_time": "2023-09-22T15:22:07.878549300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Modèle final\n",
    "model = KNeighborsClassifier(n_neighbors=62,weights='distance')\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "print(model.score(X_train,y_train))\n",
    "y_predict = model.predict(X_test)\n",
    "print(model.score(X_test,y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Partie 2: classification sur le dataset *iris*\n",
    "\n",
    "Le module <code>datasets</code> de scikit-learn inclu plusieurs jeux de données permettant de tester facilement les algorithmes de la librairie: https://scikit-learn.org/stable/datasets.html\n",
    "\n",
    "Chacun de ces jeux de données se présente sous la forme d'un dictionnaire comportant les clés suivantes:\n",
    "- data : matrice $X$ des données\n",
    "- target : vecteur $y$ des données\n",
    "- target_names : liste contenant les noms des différentes classes dans le cas de données catégorielles\n",
    "- feature_names : liste contenant les noms des différents descripteurs de $X$\n",
    "- DESCR : informations concernant le jeu de données\n",
    "\n",
    "Lors de l'importation du dataset, l'option <code>return_X_y</code> permet de ne récupérer uniquement *data* et *target*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation du jeu de données *iris*\n",
    "\n",
    "- Importez le dataset *Iris* et affichez les informations décrivant ce jeu de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T15:22:10.894587100Z",
     "start_time": "2023-09-22T15:22:10.823886700Z"
    }
   },
   "outputs": [],
   "source": [
    "# importation des données du dataset Iris et affichage du descriptif\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Affichez les noms des descripteurs et des étiquettes de ce jeu de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T15:22:12.153214200Z",
     "start_time": "2023-09-22T15:22:12.129546200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Noms des descripteurs et des étiquettes\n",
    "print(iris['target_names'])\n",
    "print(iris['feature_names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Affichez les dimensions des données et des étiquettes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T15:22:13.299118200Z",
     "start_time": "2023-09-22T15:22:13.276507800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Noms des descripteurs et des étiquettes\n",
    "print(iris['data'].shape)\n",
    "print(iris['target'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La librairie <code>pandas</code> inclu diverses fonctionnalités utiles pour l'exploration de ce type de dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T15:22:14.263961300Z",
     "start_time": "2023-09-22T15:22:14.258683900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importation de pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lors de l'importation du dataset, l'option <code>as_frame</code> permet d'obtenir les données (*data* et *target*) sous la forme de *dataframes* pandas. Les méthodes <code>.info()</code> et <code>.describe()</code> permettent alors d'afficher certaines informations et statistiques relatives aux données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T15:22:15.205364100Z",
     "start_time": "2023-09-22T15:22:15.149994Z"
    }
   },
   "outputs": [],
   "source": [
    "# Affichage des informations relatives aux données X et y\n",
    "iris = datasets.load_iris(as_frame=True)\n",
    "iris['data'].info()\n",
    "iris['target'].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entraînement d'un modèle kNN sur *iris*\n",
    "\n",
    "- Séparez les données en 1 jeu d'entraînement et 1 jeu de test\n",
    "- A l'aide d'une recherche sur grille et d'une validation croisée, déterminez le paramètre $k$ optimal pour un modèle de $k$ plus proches voisins\n",
    "- Déterminez l'erreur de généralisation à l'aide du jeu de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T15:22:17.193841600Z",
     "start_time": "2023-09-22T15:22:16.461476500Z"
    }
   },
   "outputs": [],
   "source": [
    "X = iris['data']\n",
    "y = iris['target']\n",
    "\n",
    "#On split les données pour récupérer les données de train et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,train_size=0.7, random_state=1, stratify=y)\n",
    "\n",
    "# On utilise une validation croisée pour déterminer le meilleur k\n",
    "parameter = {'n_neighbors': range(1,20)}\n",
    "knn = KNeighborsClassifier(weights='distance')\n",
    "GSCV = GridSearchCV(knn, parameter, cv=5)\n",
    "GSCV.fit(X_train, y_train)\n",
    "results = GSCV.cv_results_['mean_test_score']\n",
    "\n",
    "plt.plot(np.arange(1,20), results)\n",
    "plt.show()\n",
    "\n",
    "best_k = results.argmax()\n",
    "print(f\"Best k is {best_k}\")\n",
    "\n",
    "# On applique ensuite ce k sur notre modèle\n",
    "model = KNeighborsClassifier(n_neighbors=5, weights='distance')\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "print(model.score(X_train,y_train))\n",
    "print(f\"Score de généralisation : {model.score(X_test,y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Partie 3: compléments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codage du partitionnement des données et de l'algorithme des *k* plus proches voisins\n",
    "\n",
    "Afin de mieux appréhender le fonctionnement des principales fonctions utilisées lors de cette séance, nous allons en coder une version simplifiée en python. Pour tester votre code, commencez par créer un jeu de données 2D similaires à celles utilisées dans la première partie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T15:38:38.503995500Z",
     "start_time": "2023-09-22T15:38:38.204677700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Création d'un jeu de données\n",
    "\n",
    "def create_data(center_A : [float], sig_A: float, n_A: int, center_B: [float], sig_B: float, n_B: int):\n",
    "    \n",
    "    #Création $X_A$ et $X_B$\n",
    "    \n",
    "    mean_A = center_A\n",
    "    cov_A = [[sig_A**2,0],[0,sig_A**2]]\n",
    "    mean_B = center_B\n",
    "    cov_B = [[sig_B**2,0],[0,sig_B**2]]\n",
    "    \n",
    "    X_A = np.ones((2,n_A))\n",
    "    X_B = np.ones((2,n_B))\n",
    "    \n",
    "    X_A[0], X_A[1] = numpy.random.multivariate_normal(mean_A, cov_A, size = n_A).T\n",
    "    X_B[0], X_B[1] = numpy.random.multivariate_normal(mean_B, cov_B, size = n_B).T\n",
    "    \n",
    "    # Création $Y_A$ et $Y_B$\n",
    "    \n",
    "    Y_A = np.zeros(n_A)\n",
    "    Y_B = np.ones(n_B)\n",
    "    \n",
    "    # Création des variables $X$ et $y$\n",
    "    X = np.zeros((2,n_A+n_B))\n",
    "    X[0] = numpy.append(X_A[0],X_B[0])\n",
    "    X[1] = numpy.append(X_A[1],X_B[1])\n",
    "    Y = numpy.append(Y_A,Y_B)\n",
    "    \n",
    "    # Mélange des données\n",
    "    arr = np.arange(n_A + n_B)\n",
    "    numpy.random.shuffle(arr)\n",
    "    \n",
    "    newX = X.copy()\n",
    "    newY = Y.copy()\n",
    "    for i in range(n_A + n_B):\n",
    "        newX[0][i] = X[0][arr[i]]\n",
    "        newX[1][i] = X[1][arr[i]]\n",
    "        newY[i] = Y[arr[i]]\n",
    "    \n",
    "    return newX.T, newY.T\n",
    "\n",
    "X, y = create_data([-1,-1],1,1000,[1,1],1,500)\n",
    "\n",
    "# A et B et représentation des données sur un graphe\n",
    "plt.plot(X.T[0,y==0],X.T[1, y==0],'bo', label=\"Données A d'entrainement\")\n",
    "plt.plot(X.T[0,y==1],X.T[1, y==1],'ro', label=\"Données B d'entrainement\")\n",
    "plt.xlabel('$X_1$')\n",
    "plt.ylabel('$X_2$')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Partitionnement des données\n",
    "\n",
    "- Créez une fonction <code>partage(X,y)</code> qui sépare les données en un jeu d'entraînement $(X_{train},y_{train})$ contenant 75% des données tirées aléatoirement et un jeu de test $(X_{test},y_{test})$ contenant les 25% restant.\n",
    "- Représentez sur un graphe les données d'entraînement et sur un autre graphe les données de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partage des données entre un jeu d'entraînement et un jeu de test\n",
    "\n",
    "def partage(X, y):\n",
    "    total_size = X.size\n",
    "    size_train = int(0.75*total_size)\n",
    "    size_test = total_size - size_train\n",
    "    print(f\"Total : {total_size}, Test : {size_test}, train : {size_train}\")\n",
    "    \n",
    "    X_test = np.empty(size_test)\n",
    "    X_train = np.empty(size_train)\n",
    "    \n",
    "    for i in range():\n",
    "        \n",
    "        \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Méthode des $k$ plus proches voisins\n",
    "\n",
    "- Ecrire une fonction <code>distances(X,x_new)</code> qui calcule la distance euclidienne entre le point $x_{new}$ et chacun des points de $X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction renvoyant les distances entre un point X_new et chacun des points de X\n",
    "\n",
    "def distances(X, x_new):\n",
    "    # calcul de la distance entre X_new et les données X\n",
    "    # ...\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Modifiez la fonction précédente afin qu'elle renvoie en sortie les indices correspondant aux $k$ plus proches voisins de $x_{new}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction renvoyant les indices des k plus proches voisins\n",
    "\n",
    "def kNN(X, x_new, k):\n",
    "    # indices des k plus proches voisins\n",
    "    # ...\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Afin de tester le bon fonctionnement de la fonction kNN(), représentez sur un graphe les données d'entraînement et, pour un point $x_{new}$ de votre choix, repérez sur le graphe les 4 plus proches voisins identifiés par la fonction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test de la fonction kNN()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- La dernière étape consiste à attribuer à $x_{new}$ l'étiquette majoritaire des $k$ plus proches voisins. Que peut-on faire en cas d'égalité ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction attribuant l'étiquette y_new à la donnée x_new\n",
    "\n",
    "def predict_single(X, y, x_new, k):\n",
    "    # fonction attribuant l'étiquette y_new à la donnée x_new\n",
    "    # ...\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calcul du score du modèle sur l'ensemble de test\n",
    "\n",
    "- Ecrivez une fonction qui permette de prédire l'étiquette de chaque point de l'ensemble $X_{test}$. Calculez le score d'accuracy du modèle. Comparez avec le résultat obtenu en utilisant le modèle de k plus proches voisins de scikit-learn.\n",
    "\n",
    "<br>\n",
    "\n",
    "Remarque: pour une exécution plus rapide, il serait nettement préférable de vectoriser les calculs et de faire appel à la fonction <code>numpy.spatial.distance.cdist()</code>  pour calculer les distances entre les données de test et les données d'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction prédisant l'étiquette de chacun des points de X_new et calcul du score du modèle\n",
    "\n",
    "def predict(X, y, Z, k):\n",
    "    # fonction prédisant l'étiquette de chacun des points de X_new\n",
    "    # ...\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Représentation des régions de décision\n",
    "\n",
    "- On considère à nouveau un jeu de données 2D telles que celles utilisées dans la première partie. Après avoir entraîné un modèle de k plus proches voisins avec k=1, représentez dans le plan $(x_1,x_2)$ les régions associées aux classes A et B à l'aides de couleurs différentes. Vous pourrez pour cela utiliser la fonction <code>matplotlib.pyplot.imshow()</code>. Vous ferez également apparaître les points de données sur cette carte.\n",
    "- Représentez une telle carte pour d'autres valeurs de $k$ (5 et 25 par exemple).\n",
    "- Commentez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
