{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7742625c",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h1>MU4PY115 - IA pour la physique</h1>\n",
    "<h1>TP n°2 : Régression linéaire</h1>\n",
    "</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "## Introduction\n",
    "\n",
    "<br>\n",
    "\n",
    "Dans ce notebook vous allez réaliser quelques expériences numériques avec la méthode de régression linéaire et étudier 2 méthodes de régularisation qui lui sont couramment associées appelées *régression ridge* et *régression lasso*.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb883202",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T14:42:21.508892100Z",
     "start_time": "2023-10-02T14:42:21.447500600Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (5, 5)\n",
    "plt.rcParams[\"font.size\"] = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2611e646",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Régression linéaire par la méthode des moindres carrés\n",
    "\n",
    "<br>\n",
    "\n",
    "### Données 1D linéaires\n",
    "\n",
    "Dans cette première partie vous allez utilisez la méthode de régression linéaire ordinaire pour déterminer les coefficients d'un modèle linéaire que l'on peut ajuster sur des données 1D générées artificiellement à partir d'une fonction linéaire bruitée (avec un bruit de type gaussien). \n",
    "\n",
    "<br>\n",
    "\n",
    "**Génération des données**\n",
    "\n",
    "- Créez une fonction permettant de générer un ensemble de $N$ données aléatoire $(x,y) \\in \\mathbb{R}^2$ telles que $x$ est tiré uniformément entre 0 et 1 et $y$ est de la forme\n",
    "$$ y = ax + b + \\varepsilon $$\n",
    "où $a$ et $b$ sont des contantes réelles et $\\varepsilon$ est une variable aléatoire gaussienne de moyenne nulle et de variance $\\sigma^2$.\n",
    "\n",
    "- Représentez un ensemble de données sur un graphe pour $N = 30$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd3da24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T14:42:21.723510100Z",
     "start_time": "2023-10-02T14:42:21.691898100Z"
    }
   },
   "outputs": [],
   "source": [
    "# fonction génératrice des données\n",
    "def create_data(a, b, sigma, N):\n",
    "    X = np.random.rand(N)\n",
    "    epsilon = np.random.normal(0,sigma, size=N)\n",
    "    y = a*X + b + epsilon\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b5c1d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T14:42:22.124196200Z",
     "start_time": "2023-10-02T14:42:21.929098400Z"
    }
   },
   "outputs": [],
   "source": [
    "N = 30\n",
    "a = 3\n",
    "b = 2\n",
    "sigma = 0.1\n",
    "\n",
    "X,y = create_data(a, b, sigma, N)\n",
    "plt.plot(X,y,'o', label='Données')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64d347f",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Régression linéaire ordinaire sur les données artificielles**\n",
    "\n",
    "- A l'aide des formules établies en cours, créez un vecteur $w$ dont les composantes sont les coefficients du modèle linéaire que l'on peut ajuster sur ces données. Pour inverser une matrice, utilisez la fonction <code>numpy.linalg.inv()</code>. Pour la multiplication matricielle vous pouvez utilisez la fonction <code>numpy.matmul()</code> où l'opérateur @.\n",
    "\n",
    "- Affichez à l'écran la valeurs des coefficients du modèle et représentez sur un graphe les données ainsi que le modèle linéaire obtenu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155f1725",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T14:42:22.747335800Z",
     "start_time": "2023-10-02T14:42:22.705970700Z"
    }
   },
   "outputs": [],
   "source": [
    "w = np.ones(2)\n",
    "X = np.vstack((np.ones(N), X)).T\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "w = np.matmul(np.matmul(np.linalg.inv(np.matmul(X.T,X)),X.T),y)\n",
    "\n",
    "print(w)\n",
    "# plot data\n",
    "plt.plot(X[:,1],y,'o', label='Données')\n",
    "plt.plot(X[:,1], np.matmul(X,w), label='Modèle')\n",
    "# show w values\n",
    "plt.text(0.1, 2, 'w0 = {:.2f}\\nw1 = {:.2f}'.format(w[0],w[1]))\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-02T14:42:23.542397900Z",
     "start_time": "2023-10-02T14:42:23.373070300Z"
    }
   },
   "id": "f49dc0723f1f2ce3"
  },
  {
   "cell_type": "markdown",
   "id": "1b32c018",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Régression linéaire avec scikit-learn**\n",
    "\n",
    "- Vérifiez que vous obtenez bien le même résultat en utilisant la méthode <code>LinearRegression()</code> de la bibliothèque scikit-learn. Les coefficients du modèle correspondent aux attributs <code>.coef_</code> et <code>.intercept_</code>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c398234",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T14:42:25.392603100Z",
     "start_time": "2023-10-02T14:42:25.357395600Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# create model\n",
    "model = LinearRegression()\n",
    "# fit model\n",
    "model.fit(X,y)\n",
    "# get model coefficients\n",
    "w = np.array([model.intercept_, model.coef_[1]])\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6347e8fa",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Incertitude sur l'estimation des coefficients**\n",
    "\n",
    "Si $w$ représente le vecteur des coefficients d'un modèle linéaire, l'erreur standard sur l'estimation de la composante $w_j$ est donnée par \n",
    "$$ \\sigma(w^*_j) \\;=\\; \\sigma \\, \\sqrt{\\Sigma^{-1}_{jj}} $$\n",
    "où $\\sigma$ représente l'incertitude, supposée uniforme, sur les données $y$, et $\\Sigma = X^TX$ avec $X$ la matrice $n \\times d$ des données d'entrée.\n",
    "\n",
    "<br>\n",
    "\n",
    "Estimez l'incertitude sur les coefficients que vous avez obtenus et comparez avec le résultat renvoyé par la fonction <code>scipy.stats.linregress()</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33280c6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T14:42:26.665847100Z",
     "start_time": "2023-10-02T14:42:26.646448900Z"
    }
   },
   "outputs": [],
   "source": [
    "sigma_data = np.ones(2)\n",
    "\n",
    "sum = np.matmul(X.T,X)\n",
    "sigma_w = sigma * np.sqrt(np.linalg.inv(sum)[1,1])\n",
    "print(sigma_w)\n",
    "\n",
    "from scipy.stats import linregress\n",
    "slope, intercept, r_value, p_value, std_err = linregress(X[:,1],y)\n",
    "print(std_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a4984e",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Application à des données réelles\n",
    "\n",
    "<br>\n",
    "\n",
    "Les données que vous allez utiliser sont issues d'une étude réalisée en 1989 sur 96 patients atteints d'un caner de la prostate. L'objectif de l'étude était de relier la quantité d'antigènes *prostate-specific* à différents paramètres physiologiques. Ces données se trouvent dans le fichier *data.csv*. Elles sont organisées sous la forme d'un tableau à 10 colonnes. Les 8 premières colonnes correspondent aux descripteurs suivants:\n",
    "\n",
    "1. *lcavol* : log of cancer volume\n",
    "2. *lweight* : log of prostate weight\n",
    "3. *age* : age\n",
    "4. *lbph* : log of the amount of benign prostatic hyperplasia\n",
    "5. *svi* : seminal vesicle invasion\n",
    "6. *lcp* : log of capsular penetration\n",
    "7. *gleason* : Gleason score\n",
    "8. *pgg45* : percent of Gleason scores 4 and 5\n",
    "\n",
    "La colonne 9 contient la variable à prédire *lpsa* (= log of prostate-specific antigen) et la colonne 10 contient une variable binaire 'T' ou 'F' indiquant si la donnée correspondante a été utilisée dans le jeu d'entraînement ('T') ou dans le jeu de test ('F').\n",
    "\n",
    "<br>\n",
    "\n",
    "- Pour récupérer les données dans ce fichier, utiliser la fonction <code>read_csv()</code> de la librairie <code>pandas</code>. \n",
    "- Affichez les informations relatives aux données à l'aide des fonctions <code>.info()</code> et <code>.describe()</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b175b1c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T14:42:27.794835100Z",
     "start_time": "2023-10-02T14:42:27.744790100Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data-TP2.csv')\n",
    "\n",
    "# Split the single column into multiple columns using semicolon as the delimiter\n",
    "new_columns = data['lcavol;lweight;age;lbph;svi;lcp;gleason;pgg45;lpsa;train'].str.split(';', expand=True)\n",
    "\n",
    "# Rename the new columns as needed\n",
    "new_columns.columns = ['lcavol', 'lweight', 'age', 'lbph', 'svi', 'lcp', 'gleason', 'pgg45', 'lpsa', 'train']\n",
    "\n",
    "# Now, you have a more usable DataFrame with separate columns\n",
    "df = new_columns\n",
    "\n",
    "df.info()\n",
    "df.describe()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8042a4f",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Préparation des données: partitionnement et standardisation**\n",
    "\n",
    "- Séparez les données en 1 jeu d'entraînement ($X_{train},y_{train}$) et 1 jeu de test ($X_{test},y_{test}$) en utilisant la variable fournie en colonne 10 pour sélectionner les données. \n",
    "- Vous pouvez convertir le dataframe pandas en tableau numpy à l'aide de l'attribut <code>.values</code>. Le tableau que vous aller obtenir contient des colonnes de nombre au format décimal et d'autres colonnes au format entier. Pour éviter d'éventuels problèmes liés à ces différents format lors du traitement des données, vous avez intérêt à convertir le tableau au format décimal à l'aide de la méthode <code>numpy.astype()</code>.\n",
    "- Quel est le pourcentage des données initiales utilisées pour constituer le jeu d'entraînement ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4351f9b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T14:42:51.738816Z",
     "start_time": "2023-10-02T14:42:51.707684100Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test = df[df['train'] == 'F'].values[:,:-2].astype(float)\n",
    "y_test = df[df['train'] == 'F']['lpsa'].astype(float)\n",
    "\n",
    "X_train = df[df['train'] == 'T'].values[:,:-2].astype(float)\n",
    "y_train = df[df['train'] == 'T'].values[:,-2:-1].astype(float)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print('Pourcentage de données utilisées pour l\\'entraînement: {:.2f}%'.format(100 * len(X_train) / len(df)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537c1cc5",
   "metadata": {},
   "source": [
    "Avant d'utiliser un modèle pour ajuster un jeu de données, on effectue généralement une opération de **standardisation** sur les données. La standardisation la plus courante consiste à transformer les données de façon à ce que chaque descripteur ait une moyenne nulle et une variance égale à 1:\n",
    "\n",
    "$$ x^{(i)}_j \\; \\; \\rightarrow \\; \\; \\frac{x^{(i)}_j - \\bar{x_j}}{\\sigma_j} $$\n",
    "\n",
    "ATTENTION: les valeurs de $\\bar{x_j}$ et $\\sigma_j$ doivent être calculées pour les données d'entraînement uniquement ! En effet utiliser l'ensemble des données pour évaluer ces grandeurs signifie que l'on \"contaminerait\" le processus de traitement avec les données de test, ce qui risque de fausser l'évaluation finale du modèle.\n",
    "\n",
    "- Effectuez cette transformation \"manuellement\" à l'aide de fonctions de la librairie <code>numpy</code>. Vérifiez que les données ont été correctement standardisées.\n",
    "- Effectuez cette même transformation en utilisant la classe <code>StandardScaler</code> du module <code>sklearn.preprocessing</code> de scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b48870",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T14:42:56.648960300Z",
     "start_time": "2023-10-02T14:42:56.623571400Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_stand = (X_train - np.mean(X_train, axis=0)) / np.std(X_train, axis=0)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_stand_sk = scaler.fit_transform(X_train)\n",
    "X_test_stand_sk = scaler.fit_transform(X_test)\n",
    "\n",
    "#compare the two results\n",
    "print(np.allclose(X_train_stand, X_train_stand_sk))\n",
    "\n",
    "X_train = np.copy(X_train_stand_sk)\n",
    "X_test = np.copy(X_test_stand_sk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6f12d1",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Modèle naïf**\n",
    "\n",
    "Afin de juger de la qualité des modèles que l'on construit, il peut être utile de disposer d'une valeur de référence pour l'indicateur de performance utilisé. Pour cela on peut considérer un modèle très simple (parfois appelé *modèle naïf*) qui effectuerait des prédiction en prenant en compte uniquement les valeurs des étiquettes $y$. Dans le cas d'un problème de régression, on considère en général un modèle qui prédirait systématiquement la valeur moyenne des étiquettes.\n",
    "\n",
    "- Calculez les étiquettes prédites par un tel modèle pour les données de test.\n",
    "- En utilisant la fonction <code>mean_squared_error()</code> du module <code>sklearn.metrics</code> calculez le RMSE pour les données de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dec4099",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T14:42:59.591923200Z",
     "start_time": "2023-10-02T14:42:59.511764800Z"
    }
   },
   "outputs": [],
   "source": [
    "y_naif_predict = np.mean(y_train)\n",
    "print(y_naif_predict)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# get RMSE for test data\n",
    "print(y_test.shape)\n",
    "mean_squared_error(y_test, np.ones(y_test.size)*y_naif_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c931b91e",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Régression linéaire ordinaire**\n",
    "\n",
    "- Entraînez un modèle <code> LinearRegression()</code> avec les données d'entraînement.\n",
    "- Calculez le score du modèle sur les données d'entraînement et sur les données de test à l'aide de la méthode <code>.score()</code>. A quelle grandeur correspond la valeur renvoyée ?\n",
    "- Calculez le RMSE pour les données d'entraînement et de test.\n",
    "- Représentez sur un graphique la valeur de l'étiquette prédite en fonction de l'étiquette vraie pour les données de test.\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7277c8a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T14:43:59.832715600Z",
     "start_time": "2023-10-02T14:43:59.642766600Z"
    }
   },
   "outputs": [],
   "source": [
    "linreg = LinearRegression()\n",
    "\n",
    "linreg.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Score pour le test : {linreg.score(X_test,y_test)}\")\n",
    "print(f\"Score pour le train: {linreg.score(X_train,y_train)}\")\n",
    "\n",
    "y_predict_train = linreg.predict(X_train)\n",
    "y_predict_test = linreg.predict(X_test)\n",
    "\n",
    "print(f\"RMSE pour les données d'entrainements {np.sqrt(mean_squared_error(y_train, y_predict_train))}\")\n",
    "print(f\"RMSE pour les données de test {np.sqrt(mean_squared_error(y_test, y_predict_test))}\")\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.plot(y_test, y_predict_test, 'o', fillstyle='none')\n",
    "plt.plot(y_train, y_predict_train, 'x', fillstyle='none')\n",
    "plt.xlim(0,6)\n",
    "plt.ylim(0,6)\n",
    "plt.xlabel(r'$y_{pred}$')\n",
    "plt.ylabel(r'$y_{true}$')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccca4615",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Régularisation\n",
    "\n",
    "<br>\n",
    "\n",
    "La régression linéaire ordinaire ne permet pas de contrôler la compléxité du modèle, ce qui peut conduire à des problèmes de sur-apprentissage. La solution obtenue peut aussi être parfois instable, ce qui se traduit par le fait que de petites variations dans les données d'entraînement peuvent engendrer des variations importantes des coefficients du modèle. La méthode la plus courremment employée pour résoudre ces problèmes consiste à ajouter à la fonction de coût un terme pénalisant la complexité du modèle. Ce terme de pénalité sera le plus souvent de la forme\n",
    "$$ J_{\\ell_2}(w) \\;=\\; \\|w\\|^2_{\\ell_2} \\;=\\; \\sum_{j=1}^d \\, w_j^2 \\quad\\rightarrow\\quad \\text{régression ridge}  $$\n",
    "où\n",
    "$$ J_{\\ell_1}(w) \\;=\\; \\|w\\|_{\\ell_1} \\;=\\; \\sum_{j=1}^d \\, |w_j| \\quad\\rightarrow\\quad \\text{régression lasso} $$\n",
    "\n",
    "Les coefficients du modèle vont alors déterminés par minimisation de la fonction de coût pénalisée:\n",
    "$$ R(w) \\;=\\; \\sum_{i=1}^N \\, \\left( y_i - w_0 - \\sum_{j=1}^d \\, w_j\\,x_j \\right)^2 \\;+\\; \\lambda \\,J(w) $$\n",
    "\n",
    "Le paramètre $\\lambda$ permet de contrôler l'importance du terme de pénalité. Si on choisit $\\lambda=0$ on va obtenir des coefficients $w_j$ correspondant à un modèle non pénalisé, donc potentiellement trop complexe. Au contraire, si on choisit une valeur très grande pour $\\lambda$, les coefficients $w_j$ vont tendre vers 0, ce qui correspond dans la limite $\\lambda \\rightarrow \\infty$ à un modèle constant. Le paramètre $\\lambda$ permet donc de faire varier continuement la complexité du modèle.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4262467",
   "metadata": {},
   "source": [
    "### Régression *ridge*\n",
    "\n",
    "<br>\n",
    "\n",
    "- Pourquoi la standardisation des données est-elle très importante dans le cas d'une régression *ridge* ou *lasso* ?\n",
    "- Entraînez un modèle *ridge* (module <code>sklearn.linear_model</code>) avec les données du dataset en fixant le paramètre de régularisation à une valeur très petite (10$^{-3}$) puis à une valeur élevée (10$^3$).\n",
    "- Affichez la valeur des paramètres du modèle pour ces 2 cas ainsi que celles obtenues lors de la régression linéaire ordinaire. Commentez. Vers quelle valeur vont tendre les prédictions de la régression *ridge* lorsque le paramètre de régularisation a une valeur très élevée ?\n",
    "- Entraînez à nouveau un modèle *ridge* sur ces données pour 50 valeurs du paramètre de régularisation comprises entre 10$^{-3}$ et 10$^3$. Calculez à chaque fois le RMSE pour les données d'entraînement et de test puis représentez sur un graphe l'évolution de ces grandeurs en fonction du paramètre de régularisation. Vous prendrez soin de mettre les abscisses en échelle logarithmique.\n",
    "- Représentez l'évolution des coefficients du modèle en fonction de la valeur du paramètre de régularisation.\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1dfc20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e908dab8",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Optimisation du paramètre de régularisation**\n",
    "\n",
    "Le paramètre de régularisation optimal est généralement déterminé par la méthode de validation croisée associée à une recherche sur grille. La recherche sur grille consiste à définir un ensemble de valeurs pour un ou plusieurs méta-paramètres et à entraîner le modèle pour chaque combinaison possible de ces valeurs. Lorsque cette méthode est associée à une validation croisée, cela signifie que chaque modèle entraîné est évalué par validation croisée. Une fois la procédure terminée, on peut récupérer les valeurs des méta-paramètres ayant obtenue le meilleur score de validation.\n",
    "\n",
    "<br>\n",
    "\n",
    "Dans le cas de la régression *ridge* la recherche sur grille avec validation croisée est directement implémentée dans la classe <code>ridgeCV()</code> du module <code>sklearn.linear_model</code>. \n",
    "\n",
    "- Déterminez la valeur optimale du paramètre de régularisation à l'aide d'une validation croisée à 10 groupes en utilisant la fonction <code>RidgeCV()</code>.\n",
    "- L'erreur obtenue sur le jeu de test est-elle plus grande ou plus petite que celle obtenue sur les jeux de validation ?\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039e994c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e92c855",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Régression Lasso\n",
    "\n",
    "<br>\n",
    "\n",
    "Alors que la régression *ridge* pénalise la norme $\\ell_2$ du vecteur des coefficients, la régression *lasso* pénalise la norme $\\ell_1$. Nous allons comparer ici le résutat fourni par une régression *lasso* avec celui obtenu dans la section précédente avec la régression *ridge*.\n",
    "\n",
    "- En utilisant une régression *lasso* déterminez l'erreur d'entraînement et l'erreur de test pour une série de valeurs du paramètre de régularisation (30 valeurs entre 1E-4 et 1E3). \n",
    "- Représentez sur un graphe l'évolution de ces erreurs en fonction de ce paramètre.\n",
    "- Représentez sur un graphe l'évolution des coefficients du modèle en fonction de $\\lambda$.\n",
    "- Pour différentes valeurs du paramètre de régularisation, affichez la valeur des coefficients obtenus par une régression ridge et par une régression lasso. Que remarquez-vous ?\n",
    "- Quelle est la spécificité de la régression lasso ? Quel intérêt cela peut-il présenter ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bedec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f03f488e",
   "metadata": {},
   "source": [
    "<br> \n",
    "\n",
    "## Complément\n",
    "\n",
    "<br>\n",
    "\n",
    "### Augmentation de la dimension de l'espace d'entrée\n",
    "\n",
    "<br>\n",
    "\n",
    "Les méthodes utilisées dans les parties précédentes peuvent sembler assez limitées car les données que l'on doit analyser sont rarement linéaires. Nous allons montrer ici qu'en augmentant la dimension de l'espace d'entrée il est possible de produire un modèle non linéaire tout en continuant à appliquer une régression linéaire ordinaire, ridge ou lasso.\n",
    "\n",
    "Un modèle linéaire en dimension $d$ s'écrit\n",
    "\n",
    "$$ f(x) \\;=\\; w_0 \\;+\\; w_1\\,x_1 \\;+\\; w_2\\,x_2 \\;+\\; \\dots \\;+\\; w_d\\,x_d $$\n",
    "\n",
    "où $x_j$ est la $j$-ième composante de $x \\in \\mathbb{R}^d$.\n",
    "\n",
    "Dans le cas d'une variable $x \\in \\mathbb{R}$ on a simplement $f(x) = w_0 + w_1\\,x$. Supposons maintenant que l'on crée une variable $z = [x, x^2, x^3, \\dots, x^d]^T$. Un modèle linéaire par rapport à la variable $z \\in \\mathbb{R}^d$ sera alors de la forme\n",
    "\n",
    "$$ f(z) \\;=\\; w_0 \\;+\\; w_1\\,z_1 \\;+\\; w_2\\,z_2 \\;+\\; \\dots \\;+\\; w_d\\,z_d $$\n",
    "\n",
    "soit:\n",
    "\n",
    "$$ f(x) \\;=\\; w_0 \\;+\\; w_1\\,x \\;+\\; w_2\\,x^2 \\;+\\; \\dots \\;+\\; w_d\\,x^d $$\n",
    "\n",
    "c'est à dire un modèle polynomial de degré $d$ par rapport à la variable $x \\in \\mathbb{R}$.\n",
    "\n",
    "<br>\n",
    "\n",
    "Vous allez maintenant appliquer ce principe pour effectuer un ajustement polynomial sur des données 1D issues d'une fonction sinusoïdale.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Génération des données**\n",
    "\n",
    "- Créez une fonction qui génère $N$ données aléatoirement dans l'intervalle $[0,2\\pi]$ telles que\n",
    "$$ y = \\sin(x) + \\varepsilon $$\n",
    "où $\\varepsilon$ est une variable aléatoire gaussienne de moyenne nulle et variance $\\sigma^2$.\n",
    "\n",
    "- Représentez les données sur un graphe pour $N = 20$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97f369d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95e320ed",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Ajustement polynomial**\n",
    "\n",
    "- Créez une fonction transformant le vecteur $x=[x^{(1)},\\dots,x^{(N)}]^T$ en une matrice $X$ dont la ligne $i$ est $[x^{(i)},(x^{(i)})^2,\\dots,(x^{(i)})^d]$, où $d$ est passé en argument lors de l'appel de la fonction. Vous pouvez obtenir le même résultat en utilisant la fonction <code>sklearn.preprocessing.PolynomialFeatures()</code>.\n",
    "\n",
    "- Pour $d$ = 1 à 9, effectuez une régression linéaire ordinaire sur les données transformées\n",
    "\n",
    "- Pour chacun de ces modèles, calculez les valeurs de $y$ pour 100 valeurs de $x$ régulièrement réparties entre 0 et 1.\n",
    "\n",
    "- Représentez sur une série de graphes, les données ainsi que le modèle obtenu.\n",
    "\n",
    "- Que remarquez-vous ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edec5eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9ffca8a",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Overfitting\n",
    "\n",
    "<br>\n",
    "\n",
    "Dans cette partie nous allons mettre en évidence la diminution de la performance de prédiction lorsque le modèle est en sur-apprentissage.\n",
    "\n",
    "- Ecrire une fonction qui génére un ensemble de données (du même type que précédemment) et le sépare en 1 jeu d'apprentissage et 1 jeu de test.\n",
    "- Ecrire une fonction qui, pour un jeu d'entraînement et un jeu de test donnés, entraîne un modèle polynomial de degré $d$ et calcule le RMSE pour les données d'entraînement et les données de test.\n",
    "- Ecrire une fonction tirant successivement $M$ jeux de données et calcule le RMSE moyen (d'entraînement et de test) sur ces $M$ tirages, pour un ensemble de valeurs $d$.\n",
    "- Représentez sur un graphe l'évolution des RMSE moyens en fonction de $d$ pour $d\\in{1,…,10}$. Comment évoluent ces grandeurs lorsqu'on modifie le nombre de données ?\n",
    "- Que peut-on en conclure ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b02aad3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5cbbb98",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Régularisation\n",
    "\n",
    "- Générez un jeu de données sinusïdales à l'aide de la fonction que vous avez précédemment écrite puis construire la matrice $X$ correspondant à un dévelopement polynomial de degré 9.\n",
    "- Standardisez les données de façon à ce que toutes les composantes de la variable d'entrée aient une moyenne nulle et une même variance (utilisez la fonction <code>sklearn.preprocessing.StandardScaler()</code>).\n",
    "- Effectuez une régression ridge en optimisant le paramètre de régularisation par validation croisée avec recherche sur grille.\n",
    "- Déterminez l'erreur d'entraînement et l'erreur de test du modèle ainsi obtenu.\n",
    "- Afin de visualiser l'effet de la régularisation vous pouvez représenter sur une série de graphe les données d'entraînement ainsi que le modèle obtenu pour différentes valeurs du paramètre de régularisation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f89824",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
