{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Importation-et-préparation-des-données\" data-toc-modified-id=\"Importation-et-préparation-des-données-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Importation et préparation des données</a></span></li><li><span><a href=\"#Perceptron-multi-couches\" data-toc-modified-id=\"Perceptron-multi-couches-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Perceptron multi-couches</a></span></li><li><span><a href=\"#Réseau-convolutif\" data-toc-modified-id=\"Réseau-convolutif-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Réseau convolutif</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP n°4 : réseaux neuronaux\n",
    "\n",
    "<br>\n",
    "\n",
    "L'objectif de cette séance est d'utiliser l'interface de programmation Keras afin de construire un modèle prédictif pour les données MNIST. Dans un premier temps vous allez construire et entraîner un réseau neuronal multicouche totalement connecté puis, dans un second temps, vous mettrez en oeuvre un réseau convolutif.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Exercice**\n",
    "\n",
    "- Que représentent les données ?\n",
    "- S'agit-il d'un problème de classification ou de régression ?\n",
    "- S'il s'agit d'un problème de classification, combien de classes y a t-il ?\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Importation et préparation des données\n",
    "\n",
    "<br>\n",
    "\n",
    "Les données MNIST peuvent être importée directement depuis Keras à l'aide de la méthode <code>load_data()</code> du module <code>keras.datasets.mnist</code>.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Exercice**\n",
    "\n",
    "- Combien y a t-il de données dans le jeu d'entraînement et dans le jeu de test ?\n",
    "- Sous quelle forme se présentent les données ?\n",
    "- Quelles sont les valeurs min et max de X_train ?\n",
    "- Comment sont codés les labels des données ?\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quelles informations peut-on tirer du résultat renvoyé par la cellule ci-dessous ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"label   nombre de données   indice moyen   écart type des indices\")\n",
    "\n",
    "for i in range(10):\n",
    "    index = np.where(y_train==i)[0]\n",
    "    print(\"{:5d}   {:10d}   {:15.1f}   {:15.1f}\".format(i, len(index), np.mean(index), np.std(index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Préparation des matrices d'entrée\n",
    "\n",
    "<br>\n",
    "\n",
    "Vous allez commencer par implémenter un perceptron multi-couche. Ce type de réseau prend comme donnée d'entrée une matrice de forme $N \\times d$ où $N$ est le nombre de données et $d$ est la dimension de chaque donnée qui est ici égale au nombre de pixels des images. \n",
    "\n",
    "Par ailleurs, les stratégies habituelles d'initialisation des poids dans les réseaux neuronaux nécessitent pour être efficaces que chaque descripteur des données d'entrées se comporte approximativement comme une variable aléatoire de moyenne nulle et de variance unitaire. Pour effectuer une telle transformation, on peut utiliser la fonction <code>StandardScaler()</code> de scikit-learn. Dans certains cas (lorsque les données d'entrée sont des images par exemple) il peut être plus naturel de se restreindre à un intervalle de valeurs positives. Dans ce cas, on transformera les données de façon à ce que chaque descripteur ait une valeur comprise entre 0 et 1.\n",
    "\n",
    "\n",
    "**Exercice**\n",
    "\n",
    "- Mettre X_train et X_test sous la forme de matrices $N \\times d$ où $d = 28\\times 28$ = 784.\n",
    "- Faire un changement d'échelle de façon à ce que toutes les données soient comprises dans l'intervalle $[0,1]$.\n",
    "- A l'aide de la fonction <code>astype()</code>, convertir les données au format float32 (nombre à virgule flottante codé sur 32 bits) qui est le format utilisé par défaut par tensorflow.\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Préparation des vecteurs d'étiquettes\n",
    "\n",
    "<br>\n",
    "\n",
    "Lorsqu'on charge le dataset, les étiquettes sont codées sous la forme d'un nombre entier compris entre 0 et 9. Cette façon de représenter les différentes classes présente un inconvénient: puisque les labels (1, 2, ..., 9) ont une relation d'ordre (1 < 2 < ... < 9) cette représentation tend implicitement à considérer que les classes elles-mêmes sont ordonnées (classe 1 < classe 2 < ... < classe 9). Cette forme de représentation est parfaitement adaptée à certains problèmes, par exemple si les classes sont *très froid*, *froid*, *tiède*, *chaud*, *très chaud*. En revanche, lorsque les classes ne présentent aucune relation d'ordre, il est préférable d'éviter ce type de représentation. On va alors utiliser un encodage de type *one-hot* consistant à créer une étiquette de dimension $K$ s'il y a $K$ classes. Pour une donnée appartenant à la classe $m$, toutes les composantes seront nulles sauf la composante $m$ qui aura la valeur 1.\n",
    "\n",
    "**Exercice**\n",
    "\n",
    "- En utilisant la fonction <code>keras.utils.to_categorical()</code>, créez deux variables de sortie *y_train_onehot* et *y_test_onehot* encodant les étiquettes des données d'entraînement et de test de cette façon.\n",
    "- Affichez à l'écran les 10 premières composantes de *y_train* et de *y_train_one_hot*.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Perceptron multi-couches\n",
    "\n",
    "<br>\n",
    "\n",
    "**Exercice**\n",
    "\n",
    "- Pour ce problème, combien d'unités la couche de sortie doit-elle comporter ? Quelle fonction d'activation cette couche doit-elle utiliser ?\n",
    "- Construire un réseau neuronal comportant 2 couches cachées de 100 unités avec une activation de type *relu* et 1 couche de sortie.\n",
    "- Combien de paramètres votre modèle va t-il devoir ajuster ?\n",
    "- Compiler le modèle en choisissant la fonction de coût 'categorical_crossentropy', l'algorithme de descente SGD et la métrique d'évaluation 'accuracy'.\n",
    "- Entraîner le modèle avec des valeurs de paramètres *batch_size*, *epochs* et *validation_split* égales respectivement à 32, 10 et 0,2. Quels sont les rôles de ces paramètres ?\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création du modèle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilation du modèle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement du modèle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "La méthode <code>fit()</code> renvoie comme résultat un objet de la classe <code>History</code> dont l'attribut History.history est un dictionnaire contenant les valeurs de la fonction de coût et de la métrique d'évaluation pour chaque époque:\n",
    "- History.history['loss'] : valeurs de la fonction de coût pour les données d'entraînement\n",
    "- History.history['accuracy'] : valeurs de la métrique d'évaluation pour les données d'entraînement\n",
    "- History.history['val_loss'] : valeurs de la fonction de coût pour les données de validatin\n",
    "- History.history['val_accuracy'] : valeurs de la métrique d'évaluation pour les données de validation\n",
    "\n",
    "<br>\n",
    "\n",
    "**Exercice**\n",
    "\n",
    "Représenter sur un graphe l'évolution de la fonction de coût et de la métrique d'évaluation, pour les données d'entraînement et de validation au cours de l'entraînement du réseau.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Exercice**\n",
    "\n",
    "- Optimiser les hyper-paramètres du modèle (taux d'apprentissag, nombre d'époques d'entraînement, choix de l'optimiseur, architecture du réseau, etc).\n",
    "- Déterminer la performance prédictive que l'on peut attendre du modèle pour de nouvelles données.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation du modèle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Réseau convolutif\n",
    "\n",
    "<br>\n",
    "\n",
    "Pour obtenir de bons résultats avec des réseaux neuronaux, il est généralement nécessaire de les structurer. Les réseaux totalement connectés possèdent un très grand nombre de paramètres indépendants et nécessitent d'énormes quantités de données d'entraînement pour pouvoir produire des modèles performants. Les réseaux convolutifs permettent d'obtenir d'excellents résultats pour une grande variété de problèmes, en particulier dans le domaine de l'analyse d'images.\n",
    "\n",
    "<br>\n",
    "\n",
    "Pour construire un réseau neuronal convolutif capable de traiter des images, on va utiliser des structures <code>keras.layers.Conv2D()</code> et <code>keras.layers.MaxPooling2D()</code>. Ces couches permettent de traiter des données 2D multi-canaux. Dans le cas des données MNIST, il n'y a qu'un seul canal car les images ont été enregistrées en échelle de gris. Dans le cas d'images en couleur, il y aurait 3 canaux (rouge, vert, bleu). Les données que l'on fournit en entrée au réseau doivent être représentées sous la forme d'un tableau à 4 dimensions:\n",
    "- dimension 1: numéro de la donnée\n",
    "- dimention 2: indice de la ligne\n",
    "- dimension 3: indice de la colonne\n",
    "- dimension 4: numéro de canal\n",
    "\n",
    "Keras permet en fait de mettre le numéro de canal comme première ou dernière dimension. Pour voir comment est configuré Keras on peut utiliser la commande suivante\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.image_data_format()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Exercice**\n",
    "\n",
    "Mettre les données $X$ d'entraînement et de test sous la forme de tableaux de dimension (data_num, row_num, col_num, 1).\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Exercice**\n",
    "\n",
    "Construire un réseau convolutif ayant la structure suivante:\n",
    "- 1 couche de convolution avec 10 filtres de taille $5 \\times 5$ et une activation 'relu'\n",
    "- 1 couche de pooling renvoyant la valeur maximale des entrées sur un zone 2$\\times$2 \n",
    "- 1 couche de convolution avec 20 filtres de taille $5 \\times 5$ et une activation 'relu'\n",
    "- 1 couche de pooling renvoyant la valeur maximale des entrées sur un zone 2$\\times$2 \n",
    "- 1 couche de type <code>keras.layers.Flatten()</code>; que fait cette couche ?\n",
    "- 1 couche <code>keras.layers.Dense()</code> avec une activation 'relu' et un nombre d'unités égal au nombre de sorties de la couche précédente\n",
    "- 1 couche de sortie\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Création du modèle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Exercice**\n",
    "\n",
    "Compiler et entraîner le modèle avec les paramètres suivants:\n",
    "- fonction de coût: categorical_crossentropy\n",
    "- algorithme d'optimisation: Adam\n",
    "- métrique d'évaluation: accuracy\n",
    "- taille des mini-lots: 64\n",
    "- nombre d'époques: 10\n",
    "- données utilisées pour la validation: 20%\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilation du modèle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement du modèle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Exercice**\n",
    "\n",
    "Représenter sur un graphe l'évolution de la fonciton de coût et du score du modèle au cours de l'entraînement.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Exercice**\n",
    "\n",
    "Optimiser le modèle (en particulier le taux d'apprentissage) puis calculer la performance prédictive que l'on peut en attendre.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Compléments\n",
    "\n",
    "<br>\n",
    "\n",
    "- Etudiez comment varie la vitesse de convergence de l'algorithme en fonction de la taille des mini-lots utilisés. \n",
    "\n",
    "- A l'aide de la documentation de keras, vous pouvez ajouter dans votre réseau des couches de *dropout* ou des couches de renormalisation par lot (*batch normalization*) afin d'étudier comment ces couches supplémentaires peuvent affecter l'entraînement du réseau et ses performances.\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
